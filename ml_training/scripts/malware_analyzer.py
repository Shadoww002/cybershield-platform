import joblib
import numpy as np
from typing import Dict, Any
import math

class MalwareDetector:
    """ML-based malware detection using Random Forest"""
    
    def __init__(self, model_path='models/malware_detector_rf.pkl'):
        try:
            self.model = joblib.load(model_path)
            self.scaler = joblib.load('models/scaler_malware.pkl')
        except FileNotFoundError:
            print("Warning: Model files not found. Using mock detection.")
            self.model = None
            self.scaler = None
    
    def extract_features(self, file_bytes: bytes) -> np.ndarray:
        """Extract 87 features from file"""
        features = []
        
        # Basic features
        features.append(len(file_bytes))  # File size
        features.append(self._calculate_entropy(file_bytes))
        
        # Byte histogram (top 50)
        hist = [file_bytes.count(bytes([i])) / len(file_bytes) 
                for i in range(256)]
        features.extend(hist[:50])
        
        # String analysis
        features.append(self._count_printable(file_bytes))
        features.append(self._count_suspicious_strings(file_bytes))
        
        # PE-specific or padding
        if file_bytes[:2] == b'MZ':
            features.extend(self._extract_pe_features(file_bytes))
        else:
            features.extend([0] * 35)
        
        return np.array(features[:87])
    
    def analyze(self, file_bytes: bytes) -> Dict[str, Any]:
        """Analyze file and return threat assessment"""
        if self.model is None:
            # Fallback: simple heuristics
            entropy = self._calculate_entropy(file_bytes)
            suspicious_count = self._count_suspicious_strings(file_bytes)
            
            threat_score = min(100, (entropy * 10) + (suspicious_count * 5))
            is_malicious = threat_score > 50
            
            return {
                'is_malicious': is_malicious,
                'confidence': 0.85 if is_malicious else 0.75,
                'threat_score': threat_score,
                'model_version': '2.0.0',
                'features_analyzed': 87,
                'detection_method': 'heuristic'
            }
        
        # Use ML model
        features = self.extract_features(file_bytes)
        features_scaled = self.scaler.transform([features])
        
        prediction = self.model.predict(features_scaled)[0]
        probabilities = self.model.predict_proba(features_scaled)[0]
        
        return {
            'is_malicious': bool(prediction),
            'confidence': float(max(probabilities)),
            'threat_score': float(probabilities[1] * 100),
            'model_version': '2.0.0',
            'features_analyzed': 87,
            'detection_method': 'ml_model'
        }
    
    def _calculate_entropy(self, data: bytes) -> float:
        """Calculate Shannon entropy"""
        if not data:
            return 0
        entropy = 0
        for x in range(256):
            p_x = data.count(bytes([x])) / len(data)
            if p_x > 0:
                entropy += - p_x * math.log2(p_x)
        return entropy
    
    def _count_printable(self, data: bytes) -> int:
        """Count printable characters"""
        return sum(1 for b in data if 32 <= b <= 126)
    
    def _count_suspicious_strings(self, data: bytes) -> int:
        """Count suspicious API calls and strings"""
        suspicious = [
            b'CreateRemoteThread', b'VirtualAllocEx', 
            b'WriteProcessMemory', b'LoadLibrary',
            b'GetProcAddress', b'WinExec'
        ]
        return sum(1 for s in suspicious if s in data)
    
    def _extract_pe_features(self, data: bytes) -> list:
        """Extract PE header features"""
        features = [0] * 35
        try:
            features[0] = data.count(b'.text')
            features[1] = data.count(b'.data')
            features[2] = data.count(b'.rdata')
            features[3] = data.count(b'kernel32')
            features[4] = data.count(b'user32')
        except:
            pass
        return features